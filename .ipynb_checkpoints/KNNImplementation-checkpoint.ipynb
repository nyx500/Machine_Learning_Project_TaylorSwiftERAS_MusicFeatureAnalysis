{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2c840f-83df-43fe-9e81-fffd215f5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa1779f-253a-4556-8360-1fe6bbd692e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>track_number</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome To New York (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4WUepByoeqcedHoYhSNHRt</td>\n",
       "      <td>spotify:track:4WUepByoeqcedHoYhSNHRt</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>116.998</td>\n",
       "      <td>0.685</td>\n",
       "      <td>79</td>\n",
       "      <td>212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blank Space (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0108kcWLnn2HlH2kedi1gn</td>\n",
       "      <td>spotify:track:0108kcWLnn2HlH2kedi1gn</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>-5.376</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>96.057</td>\n",
       "      <td>0.701</td>\n",
       "      <td>79</td>\n",
       "      <td>231833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Style (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3Vpk1hfMAQme8VJ0SNRSkd</td>\n",
       "      <td>spotify:track:3Vpk1hfMAQme8VJ0SNRSkd</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>94.868</td>\n",
       "      <td>0.305</td>\n",
       "      <td>80</td>\n",
       "      <td>231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Out Of The Woods (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1OcSfkeCg9hRC2sFKB4IMJ</td>\n",
       "      <td>spotify:track:1OcSfkeCg9hRC2sFKB4IMJ</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>-5.968</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>92.021</td>\n",
       "      <td>0.206</td>\n",
       "      <td>79</td>\n",
       "      <td>235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All You Had To Do Was Stay (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2k0ZEeAqzvYMcx9Qt5aClQ</td>\n",
       "      <td>spotify:track:2k0ZEeAqzvYMcx9Qt5aClQ</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-5.579</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>96.997</td>\n",
       "      <td>0.520</td>\n",
       "      <td>78</td>\n",
       "      <td>193289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shake It Off (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>6</td>\n",
       "      <td>50yNTF0Od55qnHLxYsA5Pw</td>\n",
       "      <td>spotify:track:50yNTF0Od55qnHLxYsA5Pw</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-5.693</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>160.058</td>\n",
       "      <td>0.917</td>\n",
       "      <td>77</td>\n",
       "      <td>219209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I Wish You Would (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3FxJDucHWdw6caWTKO5b23</td>\n",
       "      <td>spotify:track:3FxJDucHWdw6caWTKO5b23</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>-6.528</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>118.009</td>\n",
       "      <td>0.539</td>\n",
       "      <td>77</td>\n",
       "      <td>207650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bad Blood (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>8</td>\n",
       "      <td>7oZONwFiFIErZcXAtTu7FY</td>\n",
       "      <td>spotify:track:7oZONwFiFIErZcXAtTu7FY</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>-6.438</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>169.971</td>\n",
       "      <td>0.363</td>\n",
       "      <td>77</td>\n",
       "      <td>211103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wildest Dreams (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>9</td>\n",
       "      <td>27exgla7YBw9DUNNcTIpjy</td>\n",
       "      <td>spotify:track:27exgla7YBw9DUNNcTIpjy</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>-7.480</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>139.985</td>\n",
       "      <td>0.514</td>\n",
       "      <td>77</td>\n",
       "      <td>220433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How You Get The Girl (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>10</td>\n",
       "      <td>733OhaXQIHY7BKtY3vnSkn</td>\n",
       "      <td>spotify:track:733OhaXQIHY7BKtY3vnSkn</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>-5.798</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>119.997</td>\n",
       "      <td>0.538</td>\n",
       "      <td>77</td>\n",
       "      <td>247533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name album release_date  \\\n",
       "0         Welcome To New York (Taylor's Version)  1989   27/10/2023   \n",
       "1                 Blank Space (Taylor's Version)  1989   27/10/2023   \n",
       "2                       Style (Taylor's Version)  1989   27/10/2023   \n",
       "3            Out Of The Woods (Taylor's Version)  1989   27/10/2023   \n",
       "4  All You Had To Do Was Stay (Taylor's Version)  1989   27/10/2023   \n",
       "5                Shake It Off (Taylor's Version)  1989   27/10/2023   \n",
       "6            I Wish You Would (Taylor's Version)  1989   27/10/2023   \n",
       "7                   Bad Blood (Taylor's Version)  1989   27/10/2023   \n",
       "8              Wildest Dreams (Taylor's Version)  1989   27/10/2023   \n",
       "9        How You Get The Girl (Taylor's Version)  1989   27/10/2023   \n",
       "\n",
       "   track_number                      id                                   uri  \\\n",
       "0             1  4WUepByoeqcedHoYhSNHRt  spotify:track:4WUepByoeqcedHoYhSNHRt   \n",
       "1             2  0108kcWLnn2HlH2kedi1gn  spotify:track:0108kcWLnn2HlH2kedi1gn   \n",
       "2             3  3Vpk1hfMAQme8VJ0SNRSkd  spotify:track:3Vpk1hfMAQme8VJ0SNRSkd   \n",
       "3             4  1OcSfkeCg9hRC2sFKB4IMJ  spotify:track:1OcSfkeCg9hRC2sFKB4IMJ   \n",
       "4             5  2k0ZEeAqzvYMcx9Qt5aClQ  spotify:track:2k0ZEeAqzvYMcx9Qt5aClQ   \n",
       "5             6  50yNTF0Od55qnHLxYsA5Pw  spotify:track:50yNTF0Od55qnHLxYsA5Pw   \n",
       "6             7  3FxJDucHWdw6caWTKO5b23  spotify:track:3FxJDucHWdw6caWTKO5b23   \n",
       "7             8  7oZONwFiFIErZcXAtTu7FY  spotify:track:7oZONwFiFIErZcXAtTu7FY   \n",
       "8             9  27exgla7YBw9DUNNcTIpjy  spotify:track:27exgla7YBw9DUNNcTIpjy   \n",
       "9            10  733OhaXQIHY7BKtY3vnSkn  spotify:track:733OhaXQIHY7BKtY3vnSkn   \n",
       "\n",
       "   acousticness  danceability  energy  instrumentalness  liveness  loudness  \\\n",
       "0      0.009420         0.757   0.610          0.000037    0.3670    -4.840   \n",
       "1      0.088500         0.733   0.733          0.000000    0.1680    -5.376   \n",
       "2      0.000421         0.511   0.822          0.019700    0.0899    -4.785   \n",
       "3      0.000537         0.545   0.885          0.000056    0.3850    -5.968   \n",
       "4      0.000656         0.588   0.721          0.000000    0.1310    -5.579   \n",
       "5      0.012100         0.636   0.808          0.000022    0.3590    -5.693   \n",
       "6      0.003540         0.670   0.858          0.000013    0.0687    -6.528   \n",
       "7      0.036200         0.618   0.683          0.000000    0.3050    -6.438   \n",
       "8      0.043600         0.589   0.674          0.000072    0.1120    -7.480   \n",
       "9      0.001960         0.758   0.691          0.000011    0.0939    -5.798   \n",
       "\n",
       "   speechiness    tempo  valence  popularity  duration_ms  \n",
       "0       0.0327  116.998    0.685          79       212600  \n",
       "1       0.0670   96.057    0.701          79       231833  \n",
       "2       0.0397   94.868    0.305          80       231000  \n",
       "3       0.0447   92.021    0.206          79       235800  \n",
       "4       0.0317   96.997    0.520          78       193289  \n",
       "5       0.0729  160.058    0.917          77       219209  \n",
       "6       0.0439  118.009    0.539          77       207650  \n",
       "7       0.1940  169.971    0.363          77       211103  \n",
       "8       0.0656  139.985    0.514          77       220433  \n",
       "9       0.0515  119.997    0.538          77       247533  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "df = pd.read_csv('taylor_swift_processed.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317e7872-f699-4dcd-a072-be3fca570693",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Drop the annoying 'Unnamed' index...\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save this to csv to get rid of that annoying index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5212\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop the annoying 'Unnamed' index...\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df\n",
    "# Save this to csv to get rid of that annoying index\n",
    "df.to_csv('taylor_swift_processed.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e2f9522-1935-47b4-94dc-7204e5802fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>track_number</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome To New York (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4WUepByoeqcedHoYhSNHRt</td>\n",
       "      <td>spotify:track:4WUepByoeqcedHoYhSNHRt</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>116.998</td>\n",
       "      <td>0.685</td>\n",
       "      <td>79</td>\n",
       "      <td>212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blank Space (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0108kcWLnn2HlH2kedi1gn</td>\n",
       "      <td>spotify:track:0108kcWLnn2HlH2kedi1gn</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>-5.376</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>96.057</td>\n",
       "      <td>0.701</td>\n",
       "      <td>79</td>\n",
       "      <td>231833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Style (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3Vpk1hfMAQme8VJ0SNRSkd</td>\n",
       "      <td>spotify:track:3Vpk1hfMAQme8VJ0SNRSkd</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>94.868</td>\n",
       "      <td>0.305</td>\n",
       "      <td>80</td>\n",
       "      <td>231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Out Of The Woods (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1OcSfkeCg9hRC2sFKB4IMJ</td>\n",
       "      <td>spotify:track:1OcSfkeCg9hRC2sFKB4IMJ</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>-5.968</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>92.021</td>\n",
       "      <td>0.206</td>\n",
       "      <td>79</td>\n",
       "      <td>235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All You Had To Do Was Stay (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2k0ZEeAqzvYMcx9Qt5aClQ</td>\n",
       "      <td>spotify:track:2k0ZEeAqzvYMcx9Qt5aClQ</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-5.579</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>96.997</td>\n",
       "      <td>0.520</td>\n",
       "      <td>78</td>\n",
       "      <td>193289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Our Song</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>24/10/2006</td>\n",
       "      <td>11</td>\n",
       "      <td>15DeqWWQB4dcEWzJg15VrN</td>\n",
       "      <td>spotify:track:15DeqWWQB4dcEWzJg15VrN</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-4.931</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>89.011</td>\n",
       "      <td>0.539</td>\n",
       "      <td>76</td>\n",
       "      <td>201106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>I'm Only Me When I'm With You</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>24/10/2006</td>\n",
       "      <td>12</td>\n",
       "      <td>0JIdBrXGSJXS72zjF9ss9u</td>\n",
       "      <td>spotify:track:0JIdBrXGSJXS72zjF9ss9u</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-3.629</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>143.964</td>\n",
       "      <td>0.518</td>\n",
       "      <td>61</td>\n",
       "      <td>213053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Invisible</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>24/10/2006</td>\n",
       "      <td>13</td>\n",
       "      <td>5OOd01o2YS1QFwdpVLds3r</td>\n",
       "      <td>spotify:track:5OOd01o2YS1QFwdpVLds3r</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>-5.723</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>96.001</td>\n",
       "      <td>0.233</td>\n",
       "      <td>58</td>\n",
       "      <td>203226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>A Perfectly Good Heart</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>24/10/2006</td>\n",
       "      <td>14</td>\n",
       "      <td>1spLfUJxtyVyiKKTegQ2r4</td>\n",
       "      <td>spotify:track:1spLfUJxtyVyiKKTegQ2r4</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-5.726</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>156.092</td>\n",
       "      <td>0.268</td>\n",
       "      <td>56</td>\n",
       "      <td>220146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Teardrops on My Guitar - Pop Version</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>24/10/2006</td>\n",
       "      <td>15</td>\n",
       "      <td>4pJi1rVt9GNegU9kywjg4z</td>\n",
       "      <td>spotify:track:4pJi1rVt9GNegU9kywjg4z</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>-3.827</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>199.997</td>\n",
       "      <td>0.483</td>\n",
       "      <td>57</td>\n",
       "      <td>179066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name         album release_date  \\\n",
       "0           Welcome To New York (Taylor's Version)          1989   27/10/2023   \n",
       "1                   Blank Space (Taylor's Version)          1989   27/10/2023   \n",
       "2                         Style (Taylor's Version)          1989   27/10/2023   \n",
       "3              Out Of The Woods (Taylor's Version)          1989   27/10/2023   \n",
       "4    All You Had To Do Was Stay (Taylor's Version)          1989   27/10/2023   \n",
       "..                                             ...           ...          ...   \n",
       "525                                       Our Song  Taylor Swift   24/10/2006   \n",
       "526                  I'm Only Me When I'm With You  Taylor Swift   24/10/2006   \n",
       "527                                      Invisible  Taylor Swift   24/10/2006   \n",
       "528                         A Perfectly Good Heart  Taylor Swift   24/10/2006   \n",
       "529           Teardrops on My Guitar - Pop Version  Taylor Swift   24/10/2006   \n",
       "\n",
       "     track_number                      id  \\\n",
       "0               1  4WUepByoeqcedHoYhSNHRt   \n",
       "1               2  0108kcWLnn2HlH2kedi1gn   \n",
       "2               3  3Vpk1hfMAQme8VJ0SNRSkd   \n",
       "3               4  1OcSfkeCg9hRC2sFKB4IMJ   \n",
       "4               5  2k0ZEeAqzvYMcx9Qt5aClQ   \n",
       "..            ...                     ...   \n",
       "525            11  15DeqWWQB4dcEWzJg15VrN   \n",
       "526            12  0JIdBrXGSJXS72zjF9ss9u   \n",
       "527            13  5OOd01o2YS1QFwdpVLds3r   \n",
       "528            14  1spLfUJxtyVyiKKTegQ2r4   \n",
       "529            15  4pJi1rVt9GNegU9kywjg4z   \n",
       "\n",
       "                                      uri  acousticness  danceability  energy  \\\n",
       "0    spotify:track:4WUepByoeqcedHoYhSNHRt      0.009420         0.757   0.610   \n",
       "1    spotify:track:0108kcWLnn2HlH2kedi1gn      0.088500         0.733   0.733   \n",
       "2    spotify:track:3Vpk1hfMAQme8VJ0SNRSkd      0.000421         0.511   0.822   \n",
       "3    spotify:track:1OcSfkeCg9hRC2sFKB4IMJ      0.000537         0.545   0.885   \n",
       "4    spotify:track:2k0ZEeAqzvYMcx9Qt5aClQ      0.000656         0.588   0.721   \n",
       "..                                    ...           ...           ...     ...   \n",
       "525  spotify:track:15DeqWWQB4dcEWzJg15VrN      0.111000         0.668   0.672   \n",
       "526  spotify:track:0JIdBrXGSJXS72zjF9ss9u      0.004520         0.563   0.934   \n",
       "527  spotify:track:5OOd01o2YS1QFwdpVLds3r      0.637000         0.612   0.394   \n",
       "528  spotify:track:1spLfUJxtyVyiKKTegQ2r4      0.003490         0.483   0.751   \n",
       "529  spotify:track:4pJi1rVt9GNegU9kywjg4z      0.040200         0.459   0.753   \n",
       "\n",
       "     instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "0            0.000037    0.3670    -4.840       0.0327  116.998    0.685   \n",
       "1            0.000000    0.1680    -5.376       0.0670   96.057    0.701   \n",
       "2            0.019700    0.0899    -4.785       0.0397   94.868    0.305   \n",
       "3            0.000056    0.3850    -5.968       0.0447   92.021    0.206   \n",
       "4            0.000000    0.1310    -5.579       0.0317   96.997    0.520   \n",
       "..                ...       ...       ...          ...      ...      ...   \n",
       "525          0.000000    0.3290    -4.931       0.0303   89.011    0.539   \n",
       "526          0.000807    0.1030    -3.629       0.0646  143.964    0.518   \n",
       "527          0.000000    0.1470    -5.723       0.0243   96.001    0.233   \n",
       "528          0.000000    0.1280    -5.726       0.0365  156.092    0.268   \n",
       "529          0.000000    0.0863    -3.827       0.0537  199.997    0.483   \n",
       "\n",
       "     popularity  duration_ms  \n",
       "0            79       212600  \n",
       "1            79       231833  \n",
       "2            80       231000  \n",
       "3            79       235800  \n",
       "4            78       193289  \n",
       "..          ...          ...  \n",
       "525          76       201106  \n",
       "526          61       213053  \n",
       "527          58       203226  \n",
       "528          56       220146  \n",
       "529          57       179066  \n",
       "\n",
       "[530 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('taylor_swift_processed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ff836a-a4db-4b3d-a9b2-d4dd6f14849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://medium.com/analytics-vidhya/why-is-scaling-required-in-knn-and-k-means-8129e4d88ed7\n",
    "# Both K-nearest neighbour and K-means clustering algorithm are \"distance-based algorthims\"\n",
    "# This means that the model will be biased/skewed in favour of variables with higher magnitudes (and therefore greater distances),\n",
    "# imparting too much meaning to them. As such, the values need to be scaled to reduce bias towards variables with higher magnitudes.\n",
    "# We want to give equal weightage to all the variables!\n",
    "# Therefore, we will calculate the z-values for all the audio attributes using numpy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a8657f-ca93-4aa2-8664-a114d6d7d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'album', 'release_date', 'track_number', 'id', 'uri',\n",
      "       'acousticness', 'danceability', 'energy', 'instrumentalness',\n",
      "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'popularity',\n",
      "       'duration_ms'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
       "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, extract the features (dependent variables --> the audio attributes for each track) that will play the role of inputs\n",
    "# to the machine-learning algorithms\n",
    "\n",
    "# Get list of column names from dataset\n",
    "column_names = df.columns\n",
    "print(column_names)\n",
    "# Extract the columns which form the musical audio attributes (therefore from 'acousticness' to 'valence', so indices 6 to 15)\n",
    "features_matrix_columns = column_names[6:15]\n",
    "features_matrix_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97bcec9e-e1fe-4025-968d-f13b60bae41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>116.998</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>-5.376</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>96.057</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>94.868</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>-5.968</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>92.021</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-5.579</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>96.997</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-4.931</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>89.011</td>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-3.629</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>143.964</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>-5.723</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>96.001</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-5.726</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>156.092</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>-3.827</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>199.997</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  liveness  loudness  \\\n",
       "0        0.009420         0.757   0.610          0.000037    0.3670    -4.840   \n",
       "1        0.088500         0.733   0.733          0.000000    0.1680    -5.376   \n",
       "2        0.000421         0.511   0.822          0.019700    0.0899    -4.785   \n",
       "3        0.000537         0.545   0.885          0.000056    0.3850    -5.968   \n",
       "4        0.000656         0.588   0.721          0.000000    0.1310    -5.579   \n",
       "..            ...           ...     ...               ...       ...       ...   \n",
       "525      0.111000         0.668   0.672          0.000000    0.3290    -4.931   \n",
       "526      0.004520         0.563   0.934          0.000807    0.1030    -3.629   \n",
       "527      0.637000         0.612   0.394          0.000000    0.1470    -5.723   \n",
       "528      0.003490         0.483   0.751          0.000000    0.1280    -5.726   \n",
       "529      0.040200         0.459   0.753          0.000000    0.0863    -3.827   \n",
       "\n",
       "     speechiness    tempo  valence  \n",
       "0         0.0327  116.998    0.685  \n",
       "1         0.0670   96.057    0.701  \n",
       "2         0.0397   94.868    0.305  \n",
       "3         0.0447   92.021    0.206  \n",
       "4         0.0317   96.997    0.520  \n",
       "..           ...      ...      ...  \n",
       "525       0.0303   89.011    0.539  \n",
       "526       0.0646  143.964    0.518  \n",
       "527       0.0243   96.001    0.233  \n",
       "528       0.0365  156.092    0.268  \n",
       "529       0.0537  199.997    0.483  \n",
       "\n",
       "[530 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now get the lists of values for these columns\n",
    "features_matrix = df[features_matrix_columns]\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f5f55b-5b12-4154-b821-21c03e274fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              1989\n",
       "1              1989\n",
       "2              1989\n",
       "3              1989\n",
       "4              1989\n",
       "           ...     \n",
       "525    Taylor Swift\n",
       "526    Taylor Swift\n",
       "527    Taylor Swift\n",
       "528    Taylor Swift\n",
       "529    Taylor Swift\n",
       "Name: album, Length: 530, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract the 'target array' from the datarame, i.e. album name (the label we want to predict with K-NN)\n",
    "target_array = df['album']\n",
    "target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1cf4e0-40ca-4918-a043-5c48b2a7f2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.947357</td>\n",
       "      <td>1.517974</td>\n",
       "      <td>0.184744</td>\n",
       "      <td>-0.119676</td>\n",
       "      <td>1.430510</td>\n",
       "      <td>0.906906</td>\n",
       "      <td>-0.329855</td>\n",
       "      <td>-0.177809</td>\n",
       "      <td>1.441069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.705554</td>\n",
       "      <td>1.305812</td>\n",
       "      <td>0.826824</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>0.724534</td>\n",
       "      <td>0.158057</td>\n",
       "      <td>-0.875836</td>\n",
       "      <td>1.521234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.974873</td>\n",
       "      <td>-0.656684</td>\n",
       "      <td>1.291418</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>-0.517296</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>-0.230281</td>\n",
       "      <td>-0.915469</td>\n",
       "      <td>-0.462847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.974518</td>\n",
       "      <td>-0.356121</td>\n",
       "      <td>1.620289</td>\n",
       "      <td>-0.119094</td>\n",
       "      <td>1.557036</td>\n",
       "      <td>0.523107</td>\n",
       "      <td>-0.159157</td>\n",
       "      <td>-1.010368</td>\n",
       "      <td>-0.958868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.974154</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.764182</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.228394</td>\n",
       "      <td>0.655464</td>\n",
       "      <td>-0.344080</td>\n",
       "      <td>-0.844503</td>\n",
       "      <td>0.614369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>-0.636756</td>\n",
       "      <td>0.731207</td>\n",
       "      <td>0.508394</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>1.163398</td>\n",
       "      <td>0.875944</td>\n",
       "      <td>-0.363995</td>\n",
       "      <td>-1.110700</td>\n",
       "      <td>0.709564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-0.962339</td>\n",
       "      <td>-0.197000</td>\n",
       "      <td>1.876076</td>\n",
       "      <td>-0.096446</td>\n",
       "      <td>-0.425213</td>\n",
       "      <td>1.318946</td>\n",
       "      <td>0.123917</td>\n",
       "      <td>0.721050</td>\n",
       "      <td>0.604348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.971594</td>\n",
       "      <td>0.236163</td>\n",
       "      <td>-0.942810</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.115926</td>\n",
       "      <td>0.606468</td>\n",
       "      <td>-0.449344</td>\n",
       "      <td>-0.877702</td>\n",
       "      <td>-0.823590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>-0.965489</td>\n",
       "      <td>-0.904206</td>\n",
       "      <td>0.920787</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.249481</td>\n",
       "      <td>0.605447</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>1.125313</td>\n",
       "      <td>-0.648229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>-0.853241</td>\n",
       "      <td>-1.116368</td>\n",
       "      <td>0.931227</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.542601</td>\n",
       "      <td>1.251577</td>\n",
       "      <td>-0.031134</td>\n",
       "      <td>2.588799</td>\n",
       "      <td>0.428987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "0       -0.947357      1.517974  0.184744         -0.119676  1.430510   \n",
       "1       -0.705554      1.305812  0.826824         -0.120780  0.031689   \n",
       "2       -0.974873     -0.656684  1.291418          0.473250 -0.517296   \n",
       "3       -0.974518     -0.356121  1.620289         -0.119094  1.557036   \n",
       "4       -0.974154      0.024002  0.764182         -0.120780 -0.228394   \n",
       "..            ...           ...       ...               ...       ...   \n",
       "525     -0.636756      0.731207  0.508394         -0.120780  1.163398   \n",
       "526     -0.962339     -0.197000  1.876076         -0.096446 -0.425213   \n",
       "527      0.971594      0.236163 -0.942810         -0.120780 -0.115926   \n",
       "528     -0.965489     -0.904206  0.920787         -0.120780 -0.249481   \n",
       "529     -0.853241     -1.116368  0.931227         -0.120780 -0.542601   \n",
       "\n",
       "     loudness  speechiness     tempo   valence  \n",
       "0    0.906906    -0.329855 -0.177809  1.441069  \n",
       "1    0.724534     0.158057 -0.875836  1.521234  \n",
       "2    0.925620    -0.230281 -0.915469 -0.462847  \n",
       "3    0.523107    -0.159157 -1.010368 -0.958868  \n",
       "4    0.655464    -0.344080 -0.844503  0.614369  \n",
       "..        ...          ...       ...       ...  \n",
       "525  0.875944    -0.363995 -1.110700  0.709564  \n",
       "526  1.318946     0.123917  0.721050  0.604348  \n",
       "527  0.606468    -0.449344 -0.877702 -0.823590  \n",
       "528  0.605447    -0.275801  1.125313 -0.648229  \n",
       "529  1.251577    -0.031134  2.588799  0.428987  \n",
       "\n",
       "[530 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now scale the values in the features matrix: define a function to apply to each column to scale the values\n",
    "def normalize(col): # takes the column as input argument\n",
    "    mean = col.mean() \n",
    "    std = col.std() # standard deviation\n",
    "    return ((col-mean) / std) # z-score formula\n",
    "\n",
    "# Apply to features matrix per column\n",
    "scaled_features_matrix = features_matrix.apply(normalize)\n",
    "scaled_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba79c23-2047-467e-b08f-623a40f22937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ref: https://kenzotakahashi.github.io/k-nearest-neighbor-from-scratch-in-python.html\n",
    "# Ref: https://medium.com/lukasfrei/machine-learning-from-scratch-knn-b018eaab53e3\n",
    "\n",
    "# First create an auxiliary function used to calculate the Euclidian difference between two samples/rows containing n features\n",
    "def euclidianDistance(sample1, sample2):\n",
    "    # First calculate the SQUARED difference (this stops negative and positive distances from cancelling out) between the values of \n",
    "    # each feature/attribute for the two samples. We will do this by taking advantage of NumPy's vectorized operations\n",
    "    differences_between_sample_features = sample2 - sample1\n",
    "    # Square the differences\n",
    "    squared_differences_between_sample_features = np.power(differences_between_sample_features, 2)\n",
    "    # Sum up the squared differences now!\n",
    "    sum_squared_differences_between_sample_features = np.sum(squared_differences_between_sample_features)\n",
    "    # Return the square root of this summation\n",
    "    return np.sqrt(sum_squared_differences_between_sample_features)\n",
    "\n",
    "# We create a new Python class for the k-NN model, which takes in 1 input parameter which is 'k' (number of neighbours to consider)\n",
    "class KNearestNeighbourClassifier:\n",
    "    def __init__(self, k): # Python constructor function: takes in 1 input arg which is k/number of nearest neighbours\n",
    "        self.k = k\n",
    "        # Set training data features matrix and labels to empty arrays\n",
    "        # Ref: https://insidelearningmachines.com/knn_algorithm_in_python_from_scratch/\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        # A list which will later store the album-names:distances as key-value pairs in between the X_test samples and the X_train samples\n",
    "        self.distances = [] \n",
    "        # Will store the sorted distances between each test instance and each training instance with y-label of the training instance\n",
    "        self.sorted_distances = []\n",
    "        # Get the first (sorted) k neighbours/distances for each test sample and store here\n",
    "        self.k_neighbours = []\n",
    "        # Stores the weighted distances of the top K neighbour for each test sample\n",
    "        self.weighted_neighbours = []\n",
    "        # Stores the sums of the weights for the K-weighted neighbours for each test sample\n",
    "        self.weights_of_labels = []\n",
    "        # Store the y_pred labels for the test inputs\n",
    "        self.pred_labels = []\n",
    "    # 'fit' doesn't do anything because this is a lazy learning algorithm as explained above, merely STORES the features matrix X and target labels Y\n",
    "    # for the training data, ready to iterate through them to calculate and sort the distances when a test-input is entered into the 'predict' method\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Convert features and target vector from dataframes/Series to np array\n",
    "        self.X_train = X_train # Stores the features-matrix for the training data\n",
    "        self.y_train = y_train # Stores the labels/target vector for the training data\n",
    "    def predict(self, X_test):\n",
    "        # Throw an error if there was no training data entered!\n",
    "        # Ref: https://insidelearningmachines.com/knn_algorithm_in_python_from_scratch/\n",
    "        if (self.X_train.size == 0) or (self.y_train.size == 0): # checks that training data is not empty arrays\n",
    "            raise Exception('Error - Model is not trained: call \"fit\" on training data prior to \"predict\",')\n",
    "            # For every sample inside X_test, calculates the distance between that sample and every every sample in X_train\n",
    "            self.calculateDistances(X_test)\n",
    "    def calculateDistances(self, X_test):\n",
    "        # Each test sample has to be compared against each training sample and the distance calculated, as well as storing the label of the album\n",
    "        # Iterates over the test samples\n",
    "        for i in range(X_test.shape[0]):\n",
    "            # Create a new sub-list storing the distances between that test sample and ALL the training samples\n",
    "            distances_for_this_test_sample = []\n",
    "            # Iterate over the training samples for THIS test sample at index i\n",
    "            for j in range(X_train.shape[0]):\n",
    "                # Calculate every distance between the test sample and all the stored training samples\n",
    "                distance = euclidianDistance(X_test[i, :], X_train[j, :])\n",
    "                # Create a dict (associative array) storing the label/album name as the key, and the Euclidian distance between the test-sample\n",
    "                # and the train-sample as the value in the key-value pair\n",
    "                distance_for_this_train_sample = {y_train[j] : distance}\n",
    "                # Add this label-distance key-value pair to the list 'distances_for_this_test_sample' which stores all the distances\n",
    "                # between this test sample and every single training sample, labelling the training samples with the album name/key\n",
    "                distances_for_this_test_sample.append(distance_for_this_train_sample)\n",
    "            # Append the list of calculated distances to the training samples for THAT particular test-sample to the main list storing all the distances\n",
    "            self.distances.append(distances_for_this_test_sample)\n",
    "    def sortDistances(self):\n",
    "        # Ref: how to sort dicts by values, not keys https://www.freecodecamp.org/news/sort-dictionary-by-value-in-python/\n",
    "        # Use the key parameter with a lambda function for the in-built sorted method to specify the value of the key to sort by\n",
    "        for test_sample_distance_list in self.distances: # Iterate over the list of distances between each test sample and all the training samples\n",
    "            # Iterate over the list of lists storing the distances between each test-sample and each train-sample as dict with album name as the key.\n",
    "            # The x.values() statement extracts the value (the distance) from each dict in this specific test sample's list of dicts\n",
    "            # storing distances to each training sample. The list() operator casts these values into a list data type. The [0] indexer is used\n",
    "            # to extract the only value (distance) for each dict, which is the sorted function's 'key' to sort the list-of-dicts\n",
    "            # for the test sample by\n",
    "            self.sorted_distances.append(sorted(test_sample_distance_list, key=lambda x : list(x.values())[0]))\n",
    "    def getWeightedDistances(self):\n",
    "        # Iterate over list-of-dicts storing distances to training samples for each test sample\n",
    "        for test_sample_distances in self.k_neighbours:\n",
    "            # This gives more weight to closer neighbours\n",
    "            weights_for_sample = [{album_name : distance * (1 / (i + 1))} # Return the key-value pair but with distance multiplied by 1/position in list\n",
    "                                  # i is the position of the dict in the sorted list of dicts\n",
    "                                  # enumerate generates a list from each key-value pair containing the album name and distance as list elements\n",
    "                                  # 0 gets the only decomposed, list-version of each key-value pair\n",
    "                                  for i, (album_name, distance) in enumerate(list(distance_dict.items())[0] \n",
    "                                            for distance_dict in test_sample_distances)\n",
    "                                 ]\n",
    "            self.weighted_neighbours.append(weights_for_sample)\n",
    "    def getKFirstNeighbours(self):\n",
    "        #self.calculateDistances(X_test)\n",
    "        #self.sortDistances()\n",
    "        # Get the top-k distances for each test sample\n",
    "        for test_sample_distances in self.sorted_distances:\n",
    "            first_k_test_sample_distances = test_sample_distances[:self.k].copy()\n",
    "            self.k_neighbours.append(first_k_test_sample_distances)\n",
    "    def calculateWeightedNeighbourSums(self):\n",
    "        for neighbours_list in self.k_neighbours:\n",
    "            sums_of_weights = {}\n",
    "            for neighbour in neighbours_list:\n",
    "                album_name = list(neighbour.keys())[0]\n",
    "                album_weighted_distance = list(neighbour.values())[0]\n",
    "                if album_name not in sums_of_weights:\n",
    "                    sums_of_weights[album_name]  = album_weighted_distance\n",
    "                else:\n",
    "                    sums_of_weights[album_name] += album_weighted_distance\n",
    "            # sums_of_weights.items() transforms the key:value pairs for each album distance into tuples\n",
    "            # the key anonymous function extracts the value (sum of weighted distances for that album label) to sort by\n",
    "            # album_name: sum_weighted_dist uses dict comprehension to convert the tuple used for sorting back into a dictionary\n",
    "            sorted_weights = {album_name: sum_weighted_dist for album_name, sum_weighted_dist in sorted(sums_of_weights.items(), key=lambda weight_tuple: weight_tuple[1], reverse=True)}\n",
    "            # append the list of dicts storing weighted k-neighbours and their distances in the weights_of_labels list storing a sub-list for each sample\n",
    "            self.weights_of_labels.append(sorted_weights)\n",
    "    def getLabels(self):\n",
    "        for label_dict in self.weights_of_labels:\n",
    "            # Ref:https://datagy.io/python-get-dictionary-key-with-max-value/\n",
    "            max_label = max(label_dict, key=label_dict.get)\n",
    "            self.pred_labels.append(max_label)\n",
    "    def predict(self, X_test):\n",
    "        self.calculateDistances(X_test)\n",
    "        self.sortDistances()\n",
    "        self.getWeightedDistances()\n",
    "        self.getKFirstNeighbours()\n",
    "        self.calculateWeightedNeighbourSums()\n",
    "        self.getLabels()\n",
    "        return self.pred_labels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6b2a6ded-04ef-4a53-a37a-8292ca8b6460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            1989\n",
      "1            1989\n",
      "2            1989\n",
      "3            1989\n",
      "4            1989\n",
      "          ...    \n",
      "295    reputation\n",
      "296    reputation\n",
      "297    reputation\n",
      "298    reputation\n",
      "299    reputation\n",
      "Name: album, Length: 300, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = scaled_features_matrix.iloc[0:300,:].values\n",
    "y_train = target_array[0:300]\n",
    "X_test = scaled_features_matrix.iloc[301:310, :].values\n",
    "print(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e7ba15-c403-4f75-a40d-2a283dd64600",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNearestNeighbourClassifier(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "knn = KNearestNeighbourClassifier(3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1860feb2-9ba8-41e2-9e41-fc11aae3732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4716981132075472"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_matrix, target_array, test_size=0.2, random_state=123)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "knn = KNearestNeighbourClassifier(2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8677ff1e-0cde-4d8c-ae4f-9470c14a95a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbours: 0.5566037735849056\n",
      "2 neighbours: 0.3867924528301887\n",
      "3 neighbours: 0.4528301886792453\n",
      "4 neighbours: 0.36792452830188677\n",
      "5 neighbours: 0.41509433962264153\n",
      "6 neighbours: 0.44339622641509435\n",
      "7 neighbours: 0.3867924528301887\n",
      "8 neighbours: 0.36792452830188677\n",
      "9 neighbours: 0.3584905660377358\n",
      "10 neighbours: 0.36792452830188677\n",
      "11 neighbours: 0.3490566037735849\n",
      "12 neighbours: 0.33962264150943394\n",
      "13 neighbours: 0.330188679245283\n",
      "14 neighbours: 0.3018867924528302\n",
      "15 neighbours: 0.29245283018867924\n",
      "16 neighbours: 0.29245283018867924\n",
      "17 neighbours: 0.29245283018867924\n",
      "18 neighbours: 0.32075471698113206\n",
      "19 neighbours: 0.3113207547169811\n",
      "20 neighbours: 0.27358490566037735\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_features_matrix, target_array, test_size=0.2, random_state=3)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    knn = KNearestNeighbourClassifier(i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{i} neighbours: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "e226aa83-6ce3-4081-8294-34369d03edde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbours: 0.5566037735849056\n",
      "2 neighbours: 0.4811320754716981\n",
      "3 neighbours: 0.5754716981132075\n",
      "4 neighbours: 0.5660377358490566\n",
      "5 neighbours: 0.5188679245283019\n",
      "6 neighbours: 0.5094339622641509\n",
      "7 neighbours: 0.5094339622641509\n",
      "8 neighbours: 0.4811320754716981\n",
      "9 neighbours: 0.46226415094339623\n",
      "10 neighbours: 0.4716981132075472\n",
      "11 neighbours: 0.44339622641509435\n",
      "12 neighbours: 0.4339622641509434\n",
      "13 neighbours: 0.41509433962264153\n",
      "14 neighbours: 0.44339622641509435\n",
      "15 neighbours: 0.39622641509433965\n",
      "16 neighbours: 0.36792452830188677\n",
      "17 neighbours: 0.3867924528301887\n",
      "18 neighbours: 0.39622641509433965\n",
      "19 neighbours: 0.3867924528301887\n",
      "20 neighbours: 0.3867924528301887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1, 21):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_features_matrix, target_array, test_size=0.2, random_state=3)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{i} neighbours: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f37257b-1a86-49ec-82c1-7e9b6a82a8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.42000e-03 7.57000e-01 6.10000e-01 ... 3.27000e-02 1.16998e+02\n",
      "  6.85000e-01]\n",
      " [8.85000e-02 7.33000e-01 7.33000e-01 ... 6.70000e-02 9.60570e+01\n",
      "  7.01000e-01]\n",
      " [4.21000e-04 5.11000e-01 8.22000e-01 ... 3.97000e-02 9.48680e+01\n",
      "  3.05000e-01]\n",
      " ...\n",
      " [6.37000e-01 6.12000e-01 3.94000e-01 ... 2.43000e-02 9.60010e+01\n",
      "  2.33000e-01]\n",
      " [3.49000e-03 4.83000e-01 7.51000e-01 ... 3.65000e-02 1.56092e+02\n",
      "  2.68000e-01]\n",
      " [4.02000e-02 4.59000e-01 7.53000e-01 ... 5.37000e-02 1.99997e+02\n",
      "  4.83000e-01]]\n",
      "['1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights' 'Midnights'\n",
      " 'Midnights' 'Midnights' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red'\n",
      " 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red'\n",
      " 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'evermore' 'evermore' 'evermore' 'evermore' 'evermore'\n",
      " 'evermore' 'evermore' 'evermore' 'evermore' 'evermore' 'evermore'\n",
      " 'evermore' 'evermore' 'evermore' 'evermore' 'evermore' 'evermore'\n",
      " 'evermore' 'evermore' 'evermore' 'evermore' 'evermore' 'evermore'\n",
      " 'evermore' 'evermore' 'evermore' 'evermore' 'evermore' 'evermore'\n",
      " 'evermore' 'evermore' 'evermore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'folklore' 'folklore'\n",
      " 'folklore' 'folklore' 'folklore' 'folklore' 'Lover' 'Lover' 'Lover'\n",
      " 'Lover' 'Lover' 'Lover' 'Lover' 'Lover' 'Lover' 'Lover' 'Lover' 'Lover'\n",
      " 'Lover' 'Lover' 'Lover' 'Lover' 'Lover' 'Lover' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' 'reputation'\n",
      " 'reputation' 'reputation' 'reputation' 'reputation' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989'\n",
      " '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' '1989' 'Red'\n",
      " 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red'\n",
      " 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red'\n",
      " 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red' 'Red'\n",
      " 'Red' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now' 'Speak Now'\n",
      " 'Speak Now' 'Speak Now' 'Speak Now' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Fearless' 'Fearless' 'Fearless' 'Fearless' 'Fearless'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008'\n",
      " 'Live From Clear Channel Stripped 2008' 'Taylor Swift' 'Taylor Swift'\n",
      " 'Taylor Swift' 'Taylor Swift' 'Taylor Swift' 'Taylor Swift'\n",
      " 'Taylor Swift' 'Taylor Swift' 'Taylor Swift' 'Taylor Swift'\n",
      " 'Taylor Swift' 'Taylor Swift' 'Taylor Swift' 'Taylor Swift'\n",
      " 'Taylor Swift']\n"
     ]
    }
   ],
   "source": [
    "print(np.array(features_matrix))\n",
    "print(np.array(target_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a4c72d8-60bf-4182-bb42-6f77c1925bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5660377358490566\n"
     ]
    }
   ],
   "source": [
    "# Implementation 2: using np arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features_matrix, target_array, test_size=0.2)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Ref: https://www.askpython.com/python/examples/k-nearest-neighbors-from-scratch\n",
    "def predict(X_train, y_train, X_test, k):\n",
    "    predicted_labels = []\n",
    "    weights_array = 1 / (np.arange(k) + 1)\n",
    "\n",
    "    for test_sample in X_test:\n",
    "        distances = []\n",
    "        for j in range(len(X_train)):\n",
    "            test_sample_distance = euclidianDistance(np.array(X_train[j, :]) , test_sample) \n",
    "            distances.append(test_sample_distance)\n",
    "        distances = np.array(distances)\n",
    "\n",
    "        #Sorting the array while preserving the index\n",
    "        #Keeping the first K datapoints\n",
    "        indices_of_closest_neighbours = np.argsort(distances)[:k]\n",
    "        closest_distances = distances[indices_of_closest_neighbours]\n",
    "        weighted_closest_distances = closest_distances * weights_array\n",
    "\n",
    "        # Get labels of the top k neighbours\n",
    "        labels = y_train[indices_of_closest_neighbours]\n",
    "        label_weights = {}\n",
    "        for label, weighted_distance in zip(labels, weighted_closest_distances):\n",
    "            if label in label_weights:\n",
    "                label_weights[label] += weighted_distance\n",
    "            else:\n",
    "                label_weights[label] = weighted_distance\n",
    "        # Get the value from the key-value pair with the maximum value/weighted score\n",
    "        predicted_label = max(label_weights, key=label_weights.get)\n",
    "        predicted_labels.append(predicted_label)\n",
    "    return predicted_labels\n",
    "\n",
    "y_pred = predict(X_train, y_train, X_test, 1)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cd127-b82e-44a2-8497-054006bb7bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7ff38-b984-4f98-968e-df8102c96a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
