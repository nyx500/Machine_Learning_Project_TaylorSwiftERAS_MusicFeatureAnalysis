{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2c840f-83df-43fe-9e81-fffd215f5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa1779f-253a-4556-8360-1fe6bbd692e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>track_number</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome To New York (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4WUepByoeqcedHoYhSNHRt</td>\n",
       "      <td>spotify:track:4WUepByoeqcedHoYhSNHRt</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>116.998</td>\n",
       "      <td>0.685</td>\n",
       "      <td>79</td>\n",
       "      <td>212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blank Space (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0108kcWLnn2HlH2kedi1gn</td>\n",
       "      <td>spotify:track:0108kcWLnn2HlH2kedi1gn</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>-5.376</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>96.057</td>\n",
       "      <td>0.701</td>\n",
       "      <td>79</td>\n",
       "      <td>231833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Style (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3Vpk1hfMAQme8VJ0SNRSkd</td>\n",
       "      <td>spotify:track:3Vpk1hfMAQme8VJ0SNRSkd</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>94.868</td>\n",
       "      <td>0.305</td>\n",
       "      <td>80</td>\n",
       "      <td>231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Out Of The Woods (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1OcSfkeCg9hRC2sFKB4IMJ</td>\n",
       "      <td>spotify:track:1OcSfkeCg9hRC2sFKB4IMJ</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>-5.968</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>92.021</td>\n",
       "      <td>0.206</td>\n",
       "      <td>79</td>\n",
       "      <td>235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All You Had To Do Was Stay (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2k0ZEeAqzvYMcx9Qt5aClQ</td>\n",
       "      <td>spotify:track:2k0ZEeAqzvYMcx9Qt5aClQ</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-5.579</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>96.997</td>\n",
       "      <td>0.520</td>\n",
       "      <td>78</td>\n",
       "      <td>193289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shake It Off (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>6</td>\n",
       "      <td>50yNTF0Od55qnHLxYsA5Pw</td>\n",
       "      <td>spotify:track:50yNTF0Od55qnHLxYsA5Pw</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-5.693</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>160.058</td>\n",
       "      <td>0.917</td>\n",
       "      <td>77</td>\n",
       "      <td>219209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I Wish You Would (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>7</td>\n",
       "      <td>3FxJDucHWdw6caWTKO5b23</td>\n",
       "      <td>spotify:track:3FxJDucHWdw6caWTKO5b23</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>-6.528</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>118.009</td>\n",
       "      <td>0.539</td>\n",
       "      <td>77</td>\n",
       "      <td>207650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bad Blood (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>8</td>\n",
       "      <td>7oZONwFiFIErZcXAtTu7FY</td>\n",
       "      <td>spotify:track:7oZONwFiFIErZcXAtTu7FY</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>-6.438</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>169.971</td>\n",
       "      <td>0.363</td>\n",
       "      <td>77</td>\n",
       "      <td>211103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wildest Dreams (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>9</td>\n",
       "      <td>27exgla7YBw9DUNNcTIpjy</td>\n",
       "      <td>spotify:track:27exgla7YBw9DUNNcTIpjy</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>-7.480</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>139.985</td>\n",
       "      <td>0.514</td>\n",
       "      <td>77</td>\n",
       "      <td>220433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How You Get The Girl (Taylor's Version)</td>\n",
       "      <td>1989</td>\n",
       "      <td>27/10/2023</td>\n",
       "      <td>10</td>\n",
       "      <td>733OhaXQIHY7BKtY3vnSkn</td>\n",
       "      <td>spotify:track:733OhaXQIHY7BKtY3vnSkn</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>-5.798</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>119.997</td>\n",
       "      <td>0.538</td>\n",
       "      <td>77</td>\n",
       "      <td>247533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name album release_date  \\\n",
       "0         Welcome To New York (Taylor's Version)  1989   27/10/2023   \n",
       "1                 Blank Space (Taylor's Version)  1989   27/10/2023   \n",
       "2                       Style (Taylor's Version)  1989   27/10/2023   \n",
       "3            Out Of The Woods (Taylor's Version)  1989   27/10/2023   \n",
       "4  All You Had To Do Was Stay (Taylor's Version)  1989   27/10/2023   \n",
       "5                Shake It Off (Taylor's Version)  1989   27/10/2023   \n",
       "6            I Wish You Would (Taylor's Version)  1989   27/10/2023   \n",
       "7                   Bad Blood (Taylor's Version)  1989   27/10/2023   \n",
       "8              Wildest Dreams (Taylor's Version)  1989   27/10/2023   \n",
       "9        How You Get The Girl (Taylor's Version)  1989   27/10/2023   \n",
       "\n",
       "   track_number                      id                                   uri  \\\n",
       "0             1  4WUepByoeqcedHoYhSNHRt  spotify:track:4WUepByoeqcedHoYhSNHRt   \n",
       "1             2  0108kcWLnn2HlH2kedi1gn  spotify:track:0108kcWLnn2HlH2kedi1gn   \n",
       "2             3  3Vpk1hfMAQme8VJ0SNRSkd  spotify:track:3Vpk1hfMAQme8VJ0SNRSkd   \n",
       "3             4  1OcSfkeCg9hRC2sFKB4IMJ  spotify:track:1OcSfkeCg9hRC2sFKB4IMJ   \n",
       "4             5  2k0ZEeAqzvYMcx9Qt5aClQ  spotify:track:2k0ZEeAqzvYMcx9Qt5aClQ   \n",
       "5             6  50yNTF0Od55qnHLxYsA5Pw  spotify:track:50yNTF0Od55qnHLxYsA5Pw   \n",
       "6             7  3FxJDucHWdw6caWTKO5b23  spotify:track:3FxJDucHWdw6caWTKO5b23   \n",
       "7             8  7oZONwFiFIErZcXAtTu7FY  spotify:track:7oZONwFiFIErZcXAtTu7FY   \n",
       "8             9  27exgla7YBw9DUNNcTIpjy  spotify:track:27exgla7YBw9DUNNcTIpjy   \n",
       "9            10  733OhaXQIHY7BKtY3vnSkn  spotify:track:733OhaXQIHY7BKtY3vnSkn   \n",
       "\n",
       "   acousticness  danceability  energy  instrumentalness  liveness  loudness  \\\n",
       "0      0.009420         0.757   0.610          0.000037    0.3670    -4.840   \n",
       "1      0.088500         0.733   0.733          0.000000    0.1680    -5.376   \n",
       "2      0.000421         0.511   0.822          0.019700    0.0899    -4.785   \n",
       "3      0.000537         0.545   0.885          0.000056    0.3850    -5.968   \n",
       "4      0.000656         0.588   0.721          0.000000    0.1310    -5.579   \n",
       "5      0.012100         0.636   0.808          0.000022    0.3590    -5.693   \n",
       "6      0.003540         0.670   0.858          0.000013    0.0687    -6.528   \n",
       "7      0.036200         0.618   0.683          0.000000    0.3050    -6.438   \n",
       "8      0.043600         0.589   0.674          0.000072    0.1120    -7.480   \n",
       "9      0.001960         0.758   0.691          0.000011    0.0939    -5.798   \n",
       "\n",
       "   speechiness    tempo  valence  popularity  duration_ms  \n",
       "0       0.0327  116.998    0.685          79       212600  \n",
       "1       0.0670   96.057    0.701          79       231833  \n",
       "2       0.0397   94.868    0.305          80       231000  \n",
       "3       0.0447   92.021    0.206          79       235800  \n",
       "4       0.0317   96.997    0.520          78       193289  \n",
       "5       0.0729  160.058    0.917          77       219209  \n",
       "6       0.0439  118.009    0.539          77       207650  \n",
       "7       0.1940  169.971    0.363          77       211103  \n",
       "8       0.0656  139.985    0.514          77       220433  \n",
       "9       0.0515  119.997    0.538          77       247533  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "df = pd.read_csv('taylor_swift_processed.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff836a-a4db-4b3d-a9b2-d4dd6f14849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://medium.com/analytics-vidhya/why-is-scaling-required-in-knn-and-k-means-8129e4d88ed7\n",
    "# Both K-nearest neighbour and K-means clustering algorithm are \"distance-based algorthims\"\n",
    "# This means that the model will be biased/skewed in favour of variables with higher magnitudes (and therefore greater distances),\n",
    "# imparting too much meaning to them. As such, the values need to be scaled to reduce bias towards variables with higher magnitudes.\n",
    "# We want to give equal weightage to all the variables!\n",
    "# Therefore, we will calculate the z-values for all the audio attributes using numpy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a8657f-ca93-4aa2-8664-a114d6d7d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'album', 'release_date', 'track_number', 'id', 'uri',\n",
      "       'acousticness', 'danceability', 'energy', 'instrumentalness',\n",
      "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'popularity',\n",
      "       'duration_ms'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
       "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, extract the features (dependent variables --> the audio attributes for each track) that will play the role of inputs\n",
    "# to the machine-learning algorithms\n",
    "\n",
    "# Get list of column names from dataset\n",
    "column_names = df.columns\n",
    "print(column_names)\n",
    "# Extract the columns which form the musical audio attributes (therefore from 'acousticness' to 'valence', so indices 6 to 15)\n",
    "features_matrix_columns = column_names[6:15]\n",
    "features_matrix_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bcec9e-e1fe-4025-968d-f13b60bae41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>116.998</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>-5.376</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>96.057</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>94.868</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>-5.968</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>92.021</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-5.579</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>96.997</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-4.931</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>89.011</td>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-3.629</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>143.964</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>-5.723</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>96.001</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-5.726</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>156.092</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>-3.827</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>199.997</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  liveness  loudness  \\\n",
       "0        0.009420         0.757   0.610          0.000037    0.3670    -4.840   \n",
       "1        0.088500         0.733   0.733          0.000000    0.1680    -5.376   \n",
       "2        0.000421         0.511   0.822          0.019700    0.0899    -4.785   \n",
       "3        0.000537         0.545   0.885          0.000056    0.3850    -5.968   \n",
       "4        0.000656         0.588   0.721          0.000000    0.1310    -5.579   \n",
       "..            ...           ...     ...               ...       ...       ...   \n",
       "525      0.111000         0.668   0.672          0.000000    0.3290    -4.931   \n",
       "526      0.004520         0.563   0.934          0.000807    0.1030    -3.629   \n",
       "527      0.637000         0.612   0.394          0.000000    0.1470    -5.723   \n",
       "528      0.003490         0.483   0.751          0.000000    0.1280    -5.726   \n",
       "529      0.040200         0.459   0.753          0.000000    0.0863    -3.827   \n",
       "\n",
       "     speechiness    tempo  valence  \n",
       "0         0.0327  116.998    0.685  \n",
       "1         0.0670   96.057    0.701  \n",
       "2         0.0397   94.868    0.305  \n",
       "3         0.0447   92.021    0.206  \n",
       "4         0.0317   96.997    0.520  \n",
       "..           ...      ...      ...  \n",
       "525       0.0303   89.011    0.539  \n",
       "526       0.0646  143.964    0.518  \n",
       "527       0.0243   96.001    0.233  \n",
       "528       0.0365  156.092    0.268  \n",
       "529       0.0537  199.997    0.483  \n",
       "\n",
       "[530 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now get the lists of values for these columns\n",
    "features_matrix = df[features_matrix_columns]\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f5f55b-5b12-4154-b821-21c03e274fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              1989\n",
       "1              1989\n",
       "2              1989\n",
       "3              1989\n",
       "4              1989\n",
       "           ...     \n",
       "525    Taylor Swift\n",
       "526    Taylor Swift\n",
       "527    Taylor Swift\n",
       "528    Taylor Swift\n",
       "529    Taylor Swift\n",
       "Name: album, Length: 530, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract the 'target array' from the datarame, i.e. album name (the label we want to predict with K-NN)\n",
    "target_array = df['album']\n",
    "target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1cf4e0-40ca-4918-a043-5c48b2a7f2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.947357</td>\n",
       "      <td>1.517974</td>\n",
       "      <td>0.184744</td>\n",
       "      <td>-0.119676</td>\n",
       "      <td>1.430510</td>\n",
       "      <td>0.906906</td>\n",
       "      <td>-0.329855</td>\n",
       "      <td>-0.177809</td>\n",
       "      <td>1.441069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.705554</td>\n",
       "      <td>1.305812</td>\n",
       "      <td>0.826824</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>0.724534</td>\n",
       "      <td>0.158057</td>\n",
       "      <td>-0.875836</td>\n",
       "      <td>1.521234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.974873</td>\n",
       "      <td>-0.656684</td>\n",
       "      <td>1.291418</td>\n",
       "      <td>0.473250</td>\n",
       "      <td>-0.517296</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>-0.230281</td>\n",
       "      <td>-0.915469</td>\n",
       "      <td>-0.462847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.974518</td>\n",
       "      <td>-0.356121</td>\n",
       "      <td>1.620289</td>\n",
       "      <td>-0.119094</td>\n",
       "      <td>1.557036</td>\n",
       "      <td>0.523107</td>\n",
       "      <td>-0.159157</td>\n",
       "      <td>-1.010368</td>\n",
       "      <td>-0.958868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.974154</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.764182</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.228394</td>\n",
       "      <td>0.655464</td>\n",
       "      <td>-0.344080</td>\n",
       "      <td>-0.844503</td>\n",
       "      <td>0.614369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>-0.636756</td>\n",
       "      <td>0.731207</td>\n",
       "      <td>0.508394</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>1.163398</td>\n",
       "      <td>0.875944</td>\n",
       "      <td>-0.363995</td>\n",
       "      <td>-1.110700</td>\n",
       "      <td>0.709564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-0.962339</td>\n",
       "      <td>-0.197000</td>\n",
       "      <td>1.876076</td>\n",
       "      <td>-0.096446</td>\n",
       "      <td>-0.425213</td>\n",
       "      <td>1.318946</td>\n",
       "      <td>0.123917</td>\n",
       "      <td>0.721050</td>\n",
       "      <td>0.604348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.971594</td>\n",
       "      <td>0.236163</td>\n",
       "      <td>-0.942810</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.115926</td>\n",
       "      <td>0.606468</td>\n",
       "      <td>-0.449344</td>\n",
       "      <td>-0.877702</td>\n",
       "      <td>-0.823590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>-0.965489</td>\n",
       "      <td>-0.904206</td>\n",
       "      <td>0.920787</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.249481</td>\n",
       "      <td>0.605447</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>1.125313</td>\n",
       "      <td>-0.648229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>-0.853241</td>\n",
       "      <td>-1.116368</td>\n",
       "      <td>0.931227</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-0.542601</td>\n",
       "      <td>1.251577</td>\n",
       "      <td>-0.031134</td>\n",
       "      <td>2.588799</td>\n",
       "      <td>0.428987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "0       -0.947357      1.517974  0.184744         -0.119676  1.430510   \n",
       "1       -0.705554      1.305812  0.826824         -0.120780  0.031689   \n",
       "2       -0.974873     -0.656684  1.291418          0.473250 -0.517296   \n",
       "3       -0.974518     -0.356121  1.620289         -0.119094  1.557036   \n",
       "4       -0.974154      0.024002  0.764182         -0.120780 -0.228394   \n",
       "..            ...           ...       ...               ...       ...   \n",
       "525     -0.636756      0.731207  0.508394         -0.120780  1.163398   \n",
       "526     -0.962339     -0.197000  1.876076         -0.096446 -0.425213   \n",
       "527      0.971594      0.236163 -0.942810         -0.120780 -0.115926   \n",
       "528     -0.965489     -0.904206  0.920787         -0.120780 -0.249481   \n",
       "529     -0.853241     -1.116368  0.931227         -0.120780 -0.542601   \n",
       "\n",
       "     loudness  speechiness     tempo   valence  \n",
       "0    0.906906    -0.329855 -0.177809  1.441069  \n",
       "1    0.724534     0.158057 -0.875836  1.521234  \n",
       "2    0.925620    -0.230281 -0.915469 -0.462847  \n",
       "3    0.523107    -0.159157 -1.010368 -0.958868  \n",
       "4    0.655464    -0.344080 -0.844503  0.614369  \n",
       "..        ...          ...       ...       ...  \n",
       "525  0.875944    -0.363995 -1.110700  0.709564  \n",
       "526  1.318946     0.123917  0.721050  0.604348  \n",
       "527  0.606468    -0.449344 -0.877702 -0.823590  \n",
       "528  0.605447    -0.275801  1.125313 -0.648229  \n",
       "529  1.251577    -0.031134  2.588799  0.428987  \n",
       "\n",
       "[530 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now scale the values in the features matrix: define a function to apply to each column to scale the values\n",
    "def normalize(col): # takes the column as input argument\n",
    "    mean = col.mean() \n",
    "    std = col.std() # standard deviation\n",
    "    return ((col-mean) / std) # z-score formula\n",
    "\n",
    "# Apply to features matrix per column\n",
    "scaled_features_matrix = features_matrix.apply(normalize)\n",
    "scaled_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7cd127-b82e-44a2-8497-054006bb7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References to tutorials:\n",
    "# Ref: https://kenzotakahashi.github.io/k-nearest-neighbor-from-scratch-in-python.html\n",
    "# Ref: https://medium.com/lukasfrei/machine-learning-from-scratch-knn-b018eaab53e3\n",
    "\n",
    "# First create an auxiliary function used to calculate the Euclidian difference between two samples/rows containing n features\n",
    "def euclidianDistance(sample1, sample2):\n",
    "    # First calculate the SQUARED difference (this stops negative and positive distances from cancelling out) between the values of \n",
    "    # each feature/attribute for the two samples. We will do this by taking advantage of NumPy's vectorized operations\n",
    "    differences_between_sample_features = sample2 - sample1\n",
    "    # Square the differences\n",
    "    squared_differences_between_sample_features = np.power(differences_between_sample_features, 2)\n",
    "    # Sum up the squared differences now!\n",
    "    sum_squared_differences_between_sample_features = np.sum(squared_differences_between_sample_features)\n",
    "    # Return the square root of this summation\n",
    "    return np.sqrt(sum_squared_differences_between_sample_features)\n",
    "\n",
    "# We create a new Python class for the k-NN model\n",
    "# The class accepts one input parameter upon instantiation, which is 'k' (this is the number of neighbours weigh up and consider for each test sample)\n",
    "class KNearestNeighbourClassifier:\n",
    "    \n",
    "    def __init__(self, k): # Constructor function: takes in 1 input arg which is an integer storing k (nr of nearest neighbours)\n",
    "        self.k = k\n",
    "        # Initialize the training data features matrix (X_train) and labels (y_train) to empty arrays\n",
    "        # Ref: https://insidelearningmachines.com/knn_algorithm_in_python_from_scratch/\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        # This array stores the k-weights for each of the distances for the k-closest neighbours\n",
    "        # I.e. the closest neighbour is multiplied by 1, the second-closest neighbour by 1/2, the third-closest by 1/3 in the case of k=3\n",
    "        # The weights for each album-label mentioned in the k-closest neighbours are then summed up, and the label with the greatest weight is output.\n",
    "        self.weights_array = 1 / (np.arange(self.k) + 1)\n",
    "        # This will store and return the y_pred/predicted album labels for the test samples after the predict() method is called\n",
    "        self.predicted_labels = []\n",
    "        \n",
    "    # 'fit' doesn't do anything because this is a lazy learning algorithm as explained above\n",
    "    # It merely STORES the features matrix X and target labels Y for the training data, ready to use when 'predict' is called.\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Convert features and target vector from dataframes/Series to np array\n",
    "        self.X_train = X_train # Store the features-matrix for the training data\n",
    "        self.y_train = y_train # Store the labels/target vector for the training data\n",
    "\n",
    "    # Selects the k-nearest neighbors for each test sample in X_test, and then selects the label of the most heavily-weighted neighbor\n",
    "    def predict(self, X_test):\n",
    "        self.predicted_labels = []\n",
    "        # Throw an error if there was no training data entered!\n",
    "        # Ref: https://insidelearningmachines.com/knn_algorithm_in_python_from_scratch/\n",
    "        if (self.X_train.size == 0) or (self.y_train.size == 0): # checks that training data does not consist of solelyempty arrays\n",
    "            raise Exception('Error - Model is not trained: call \"fit\" on training data prior to \"predict\",')\n",
    "            \n",
    "        # Iterate over each test sample [i.e. unseen song row] in the X_test samples array\n",
    "        for test_sample in X_test:\n",
    "            # Initialize an empty list/array which will contain the distance for THIS specific test sample to every one of the training samples\n",
    "            # based on the Euclidian distance between the 2D array of selected audio features\n",
    "            test_sample_distances = []\n",
    "            # Iterate over the training data instances to measure the Euclidian distance between this iteration of test sample\n",
    "            # and all of the training samples in X_train. 'j' represents every sample in X_train [row representing a stored song]\n",
    "            for j in range(len(self.X_train)):\n",
    "                # Calculate the floating-point number representing the distance between this test sample and this train sample indexed at row j\n",
    "                # Use index slicing to get 'j' & all cols (features) from the X_train features matrix\n",
    "                test_sample_distance = euclidianDistance(np.array(self.X_train[j, :]) , test_sample)  \n",
    "                # Appends the new (floating-point) distance to the list of distances between this test sample and each one of the training samples\n",
    "                test_sample_distances.append(test_sample_distance) \n",
    "            # Converts the array of distances for this test sample to NumPy array: this enables useful NumPy function, such as argsort\n",
    "            test_sample_distances = np.array(test_sample_distances)\n",
    "    \n",
    "            # Argsort: sorts the array of distances --> returns the indices of the elements in the array that would result in the sorted array\n",
    "            # Ref: https://www.geeksforgeeks.org/numpy-argsort-in-python/\n",
    "            indices_of_closest_neighbours = np.argsort(test_sample_distances)[:self.k]\n",
    "            # Extract the sorted distances from the array of distances using the argsort indexes\n",
    "            closest_distances = test_sample_distances[indices_of_closest_neighbours]\n",
    "            # Then multiply these distances of the k-closest neighbours by the np weights array using element-wise, vectorized multiplication\n",
    "            weighted_closest_distances = closest_distances * self.weights_array\n",
    "            # Use the indices of the closest neighbours to access the actual labels/album names of these neighbours\n",
    "            labels = self.y_train[indices_of_closest_neighbours]\n",
    "            # Create a dict which will store:\n",
    "            # - Key: each album/label for the top k neighbours\n",
    "            # - Value: the summed total of its weighted distance from test sample\n",
    "            label_weights = {}\n",
    "            # Pair teh album labels with their weighted distances from the sample into tuples using the zip() function\n",
    "            # Theniterate over the paired tuples\n",
    "            # Ref: https://www.w3schools.com/python/ref_func_zip.asp\n",
    "            for label, weighted_distance in zip(labels, weighted_closest_distances):\n",
    "                # If the album name (the 'label') is not yet in the label_weight dicts, add it as a key, with the weighted distance as the value\n",
    "                if label in label_weights:\n",
    "                    label_weights[label] += weighted_distance\n",
    "                # If the album name is already in the dict, sum the new weighted distance to the existing weighted distance for that album\n",
    "                else:\n",
    "                    label_weights[label] = weighted_distance\n",
    "            # Extract the label (dict key) associated with the max weight [value] for that test sample\n",
    "            # Ref: https://datagy.io/python-get-dictionary-key-with-max-value/#:~:text=The%20simplest%20way%20to%20get,maximum%20value%20of%20any%20iterable.&text=What%20we%20can%20see%20here,max%20value%20of%20that%20iterable.\n",
    "            predicted_label = max(label_weights, key=label_weights.get)\n",
    "            # Append the label to the list of predictions for the test samples\n",
    "            self.predicted_labels.append(predicted_label)\n",
    "        # Return the completed list of predicted labels for the test samples\n",
    "        return self.predicted_labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba7ff38-b984-4f98-968e-df8102c96a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5157232704402516\n",
      "0.5157232704402516\n",
      "0.5157232704402516\n",
      "0.5157232704402516\n"
     ]
    }
   ],
   "source": [
    "# Train and test this model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(scaled_features_matrix), np.array(target_array), test_size=0.3)\n",
    "knn = KNearestNeighbourClassifier(1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred, average='micro'))\n",
    "print(recall_score(y_test, y_pred, average='micro'))\n",
    "print(f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9922c688-0c79-4f09-b275-4891aa110f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44654088050314467"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare results to scikit-learn KNeighboursClassifier...\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred2 = neigh.predict(X_test)\n",
    "accuracy_score(y_test, y_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b89f0f2-4348-4b83-899d-c69a64396ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for k: [1 1 1 1 1]\n",
      "Accuracy scores: [0.61320755 0.56603774 0.55660377 0.55660377 0.64150943]\n",
      "Precision scores: [0.61320755 0.56603774 0.55660377 0.55660377 0.64150943]\n",
      "Recall scores: [0.61320755 0.56603774 0.55660377 0.55660377 0.64150943]\n",
      "Mean Accuracy: 0.5867924528301887\n"
     ]
    }
   ],
   "source": [
    "# Performs  n-fold nested cross validation to find the best hyperparameter/value of 'k'\n",
    "# Divide the dataset into x 'folds' (x different train-test sets comprised of different inputs and labels for the training and test data)\n",
    "\n",
    "# Creates a fold with 80% training data and 20% test data split\n",
    "def createFold(X, y):\n",
    "    # Randomly shuffle the indices of the sample data\n",
    "    random_indices = np.random.permutation(len(X))\n",
    "    # Calculate the count for 80% of samples (train)\n",
    "    nr_training_samples = round(len(X) * 0.8) # 424 training samples for the 530 rows of Taylor Swift songs\n",
    "    # Calculate the count for 20% of samples (test)\n",
    "    nr_test_samples = len(X) - nr_training_samples # 106 test samples for the 530 rows of Taylor Swift songs\n",
    "    # Get the indices used to extract the train and test data\n",
    "    train_indices = random_indices[:nr_training_samples]\n",
    "    test_indices = random_indices[nr_training_samples:]\n",
    "    # Extract the training and test inputs and training and test labels using the random indices\n",
    "    X_train, y_train, X_test, y_test = X[train_indices], y[train_indices], X[test_indices], y[test_indices]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Takes in a features matrix (X) and target array of album names (y), and runs cross-validation on 'nr_outer_folds' combinations of train-test data,\n",
    "# while validating on [1...'nr_inner_folds'] values of k (nearest neighbours) for each outer fold. Then, selects value of k with greatest\n",
    "# accuracy score, and uses this value of k nearest neighbours to test on the outer-fold train-test combination\n",
    "def kNearestNeighbour_CrossValidation(X, y, nr_outer_folds, nr_inner_folds):\n",
    "    # Stores the optimal k hyperparameter for each outer fold\n",
    "    best_k_values_per_fold = []\n",
    "    # Stores accuracy scores for each outer fold\n",
    "    accuracy_values_per_fold = []\n",
    "    # Stores precision scores for each outer fold\n",
    "    precision_scores_per_fold = []\n",
    "    # Stores recall scores for each outer fold\n",
    "    recall_scores_per_fold = []\n",
    "    # Cross-validate by dividing data into different train-test splits 'nr_outer_folds' times...\n",
    "    for i in range(nr_outer_folds):\n",
    "        # Create the new combination of train-test data for this fold\n",
    "        X1_train, y1_train, X1_test, y1_test = createFold(X, y)\n",
    "        # Get the training set created in the above line of code and use it to split further into a training-and-validation set for hyperparameter tests\n",
    "        X2_train, y2_train, X2_test, y2_test = createFold(X1_train, y1_train)\n",
    "        # Stores the accuracies for each hyperparameter run on the validation set\n",
    "        inner_fold_accuracies = []\n",
    "        # j iterates from 1 to 'nr_inner_folds + 1' to iterate over 1 to 'nr_inner_folds' values for the k hyperparameter\n",
    "        for j in range(1, nr_inner_folds + 1):\n",
    "            # Create new instance of k-NN classifier that looks at j nearest neighbours\n",
    "            knn = KNearestNeighbourClassifier(j)\n",
    "            # Insert the training set for the inner fold\n",
    "            knn.fit(X2_train, y2_train)\n",
    "            # Test on the validation set for the inner fold\n",
    "            y_validation_pred = knn.predict(X2_test)\n",
    "            # Store the accuracy for this value of k-nearest neighbours\n",
    "            inner_fold_accuracies.append(accuracy_score(y2_test, y_validation_pred))\n",
    "        inner_fold_accuracies = np.array(inner_fold_accuracies)\n",
    "        # Get the value of k nearest neighbours which performed best with the highest accuracy score\n",
    "        best_k_value = np.argmax(inner_fold_accuracies) + 1\n",
    "        # Train and test the outer-fold train-test set using this hyperparameter\n",
    "        outer_knn = KNearestNeighbourClassifier(best_k_value)\n",
    "        outer_knn.fit(X1_train, y1_train)\n",
    "        y1_pred = outer_knn.predict(X1_test)\n",
    "        # Store the accuracy and precision for the outer fold in the function-scope arrays defined at the beginning of the functin\n",
    "        accuracy = accuracy_score(y1_test, y1_pred)\n",
    "        precision = precision_score(y1_test, y1_pred, average='micro') # 'micro' average: counts total true pos, false negs, false pos without weights.\n",
    "        recall = recall_score(y1_test, y1_pred, average='micro')\n",
    "        best_k_values_per_fold.append(best_k_value)\n",
    "        accuracy_values_per_fold.append(accuracy)\n",
    "        precision_scores_per_fold.append(precision)\n",
    "        recall_scores_per_fold.append(recall)\n",
    "    return np.array(best_k_values_per_fold), np.array(accuracy_values_per_fold), np.array(precision_scores_per_fold), np.array(recall_scores_per_fold)\n",
    "\n",
    "best_k_values_per_fold, accuracy_values_per_fold, precision_scores_per_fold, recall_scores_per_fold = kNearestNeighbour_CrossValidation(\n",
    "    np.array(scaled_features_matrix), np.array(target_array), 5, 6\n",
    ")\n",
    "print(f\"Best hyperparameters for k: {best_k_values_per_fold}\")\n",
    "print(f\"Accuracy scores: {accuracy_values_per_fold}\")\n",
    "print(f\"Precision scores: {precision_scores_per_fold}\")\n",
    "print(f\"Recall scores: {recall_scores_per_fold}\")\n",
    "print(f\"Mean Accuracy: {accuracy_values_per_fold.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9536ef0-de60-4e5c-8e20-ac53237a475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
